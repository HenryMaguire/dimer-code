{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SES_setup loaded globally\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from SES_setup import *\n",
    "from utils import *\n",
    "from style import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "The operators took 1.789353847503662 and have dimension 39.\n",
      "Building the RC Liouvillian took 1.836 seconds.\n",
      "It is 1521by1521. The full basis would be 2304by2304\n",
      "It took  0.6616377830505371  seconds to build the Non-secular RWA Liouvillian\n",
      "Full optical Liouvillian took 0.5699288845062256 seconds.\n",
      "Chopping reduced the sparsity from 10.104% to 10.104%\n",
      "Quantum object: dims = [[3], [3]], shape = (3, 3), type = oper, isherm = True\n",
      "Qobj data =\n",
      "[[   0.    0.    0.]\n",
      " [   0. 3535.   35.]\n",
      " [   0.   35. 3500.]]\n"
     ]
    }
   ],
   "source": [
    "#import weak_phonons as wp\n",
    "\n",
    "T_ph = 300.\n",
    "w_2 = 3500. #1.4*ev_to_inv_cm\n",
    "bias = w_2*0.01 #0.01*ev_to_inv_cm #0.0000001*ev_to_inv_cm\n",
    "V = w_2*0.01 #0.01*ev_to_inv_cm #0.00001*ev_to_inv_cm\n",
    "alpha = 1.\n",
    "alpha_EM = 5.309e-3 # inv_ps_to_inv_cm *10^-3\n",
    "N =4\n",
    "#wc = 50.\n",
    "w_0 = 100.\n",
    "Gamma = 2*w_0\n",
    "T_EM = 2000.\n",
    "\n",
    "#phonons = np.logspace(-1,np.log10(20),8)\n",
    "\n",
    "PARAMS = PARAMS_setup(bias=bias, w_2=w_2, V = V, alpha=alpha,\n",
    "                      T_EM=T_EM, T_ph =T_ph, alpha_EM=alpha_EM, shift=True,\n",
    "                      num_cpus=4, N=N, Gamma=Gamma, w_0=w_0,\n",
    "                      silent=True, exc_diff=0)\n",
    "#print PARAMS['H_sub'].eigenstates()\n",
    "H, L, L_RWA, PARAMS = get_H_and_L_RWA(PARAMS,silent=False, threshold=0.)\n",
    "\n",
    "\n",
    "evals, evecs = exciton_states(PARAMS, shift=False)\n",
    "dark, bright = evecs[0]*evecs[0].dag(), evecs[1]*evecs[1].dag()\n",
    "eig_x = (evecs[0]*evecs[1].dag() + evecs[1]*evecs[0].dag())*0.5\n",
    "ops = make_expectation_operators(PARAMS)\n",
    "site_x = (site_coherence+site_coherence.dag())\n",
    "print( PARAMS['H_sub'])\n",
    "\n",
    "H, L, L_RWA, PARAMS = get_H_and_L_RWA(PARAMS, silent=True, threshold=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Quantum object: dims = [[3, 3], [3, 3]], shape = (8, 8), type = oper, isherm = False\n",
       " Qobj data =\n",
       " [[0.         0.         0.         1.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         1.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         1.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   1.41421356 0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         1.41421356]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         0.        ]],\n",
       " Quantum object: dims = [[3, 3], [3, 3]], shape = (8, 8), type = oper, isherm = False\n",
       " Qobj data =\n",
       " [[0.         1.         0.         0.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         1.41421356 0.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         1.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         1.41421356\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         0.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         1.        ]\n",
       "  [0.         0.         0.         0.         0.         0.\n",
       "   0.         0.        ]]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qt.enr_destroy([3,3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this comparison, we need to look at two state spaces with the same size, but show that the one that\n",
    "# employs ENR uses more favourable states (higher entropy, more likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENR_basis_labels(N_1, N_2, exc):\n",
    "    state_space = set()\n",
    "    for n1 in range(N_1):\n",
    "        for n2 in range(N_2):\n",
    "            state_name  = '|{},{}|'.format(n1, n2)\n",
    "            #print (n1+n2)\n",
    "            \n",
    "            if (n1+n2)<=exc:\n",
    "                state_space.add(state_name)\n",
    "    assert qt.enr_destroy([N_1,N_2], exc)[0].shape[0] ==  len(state_space) \n",
    "    return state_space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'|4,1|', '|3,2|', '|1,4|', '|2,3|'}\n",
      "{'|4,0|', '|0,4|'}\n"
     ]
    }
   ],
   "source": [
    "print(ENR_basis_labels(5, 5, 5).difference(ENR_basis_labels(5, 5, 4)))\n",
    "print(ENR_basis_labels(5, 5, 4).difference(ENR_basis_labels(4, 4, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dims = []\n",
    "N_exc = []\n",
    "state_spaces = []\n",
    "for n in range(3,7):\n",
    "    for exc in range(n, 2*n+1):\n",
    "        stsp = ENR_basis_labels(n, n, exc)\n",
    "        \n",
    "        dims.append(len(stsp))\n",
    "        state_spaces.append(stsp)\n",
    "        N_exc.append((n,exc))\n",
    "\n",
    "print(state_spaces[0], '\\n',state_spaces[1], '\\n',state_spaces[2], '\\n',state_spaces[3])\n",
    "idx1 = 1\n",
    "idx2 = 2\n",
    "print(N_exc)\n",
    "print(dims)\n",
    "base = state_spaces[idx1]\n",
    "base_ENR = state_spaces[idx2]\n",
    "print( base, '\\n',base_ENR)\n",
    "print(N_exc[idx1], N_exc[idx2])\n",
    "print(dims)\n",
    "print( len(base), len(base_ENR))\n",
    "print( base.difference(base_ENR))\n",
    "print(base_ENR.difference(base))\n",
    "#print( base.difference(ENR_basis_labels(4, 4, 5)), ENR_basis_labels(4, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
